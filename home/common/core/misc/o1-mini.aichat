[chat-options]
model=o1-mini
stream=0
temperature=1
max_completion_tokens=25000
request_timeout=120
initial_prompt=

>>> user

